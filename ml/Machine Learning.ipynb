{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exemples de classification avec scikit-learn\n",
    "\n",
    "On va effectuer un apprentissage supervisé multi-classes avec différents algorithmes de la librairie **scikit-learn** :\n",
    "- Algorithme par analogie : K plus proches voisins\n",
    "- Algorithmes par combinaison de tests élémentaires : Arbres de décision, Forêts d'arbres décisionnels\n",
    "- Algorithmes par approche probabiliste : Classification naïve bayésienne\n",
    "- Algorithme par maximisation de la marge : Machine à vecteurs de support\n",
    "- Algorithmes par minimisation de l'erreur : Régression logistique, Algorithme du gradient stochastique, Réseau de neuronnes\n",
    "\n",
    "Avec **scikit-learn**, le principe est toujours le même :\n",
    "- Matrice de données *X* et vecteur d'étiquettes *y*\n",
    "- Séparation des bases d'apprentissage et de test : *X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, ...)*\n",
    "- Instanciation d'un algorithme de classification : *algo = XClassifier(...)*\n",
    "- Apprentissage sur la base d'apprentissage : *algo.fit(X_train, y_train)*\n",
    "- Prédiction sur la base de test : *y_pred = algo.predict(X_test)*\n",
    "- Calcul de la performance en comparant y_pred avec y_test : *accuracy_score(y_test, y_pred)*\n",
    "\n",
    "On effectuera également un apprentissage avec la librairie spécialisée de réseaux de neuronnes **Keras** qui nécessite l'installation de librairies supplémentaires : theano, mingw, libpython (sous Windows).\n",
    "\n",
    "**scikit-learn** : Scikit-learn est une bibliothèque libre Python dédiée à l'apprentissage automatique. http://scikit-learn.org\n",
    "\n",
    "**Keras** : Keras is a high-level neural networks library, written in Python and capable of running on top of either TensorFlow or Theano. https://keras.io\n",
    "\n",
    "**Theano** : Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. http://deeplearning.net/software/theano/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports usuels\n",
    "import numpy as np\n",
    "import pandas as pnd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# chargement des algorithmes scikit-learn\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# utilitaires scikit-learn\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# librairie Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# timer\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données\n",
    "\n",
    "Cet exemple utilise un dataset du MNIST voir : http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "IFrame(\"http://yann.lecun.com/exdb/mnist/\", 800, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import du dataset de 70.000 images en niveau de gris\n",
    "# écriture manuscripte des chiffres de 0 à 9\n",
    "# images étiquettées\n",
    "mnist = fetch_mldata(\"MNIST original\")\n",
    "\n",
    "# rescale the data\n",
    "X, y = mnist.data / 255., mnist.target\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# images carrées de 28 x 28 pixels\n",
    "np.sqrt(784)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adapté du MOOC machine learning Coursera Octave displayData.m\n",
    "# et étendu avec l'affichage des chiffres en parallèle des images\n",
    "# et également des écarts des prédictions\n",
    "\n",
    "def display_data(X, y=None, y_predict=None):\n",
    "    example_width = int(np.sqrt(X.shape[1]))\n",
    "\n",
    "    # Compute rows, cols\n",
    "    m, n = X.shape\n",
    "    example_height = int(n / example_width)\n",
    "\n",
    "    # Compute number of items to display\n",
    "    display_rows = int(np.floor(np.sqrt(m)))\n",
    "    display_cols = int(np.ceil(m / display_rows))\n",
    "\n",
    "    # Between images padding\n",
    "    pad = 1\n",
    "\n",
    "    # Setup blank display\n",
    "    display_array = - np.ones((pad + display_rows * (example_height + pad),\\\n",
    "                           pad + display_cols * (example_width + pad)))\n",
    "\n",
    "    # Copy each example into a patch on the display array\n",
    "    # dataset contains N pixel by N pixel grayscale images of the digit \n",
    "    curr_ex = 0\n",
    "    for j in range(display_rows):\n",
    "        for i in range(display_cols):\n",
    "            if curr_ex >= m:\n",
    "                break\n",
    "            # Get the max value of the patch\n",
    "            max_val = max(abs(X[curr_ex]))\n",
    "            display_array[(pad + j * (example_height + pad)):(pad + j * (example_height + pad))+example_height,\\\n",
    "                          (pad + i * (example_width + pad)):(pad + i * (example_width + pad))+example_width] =\\\n",
    "                            np.reshape(X[curr_ex], (example_height, example_width)) / max_val\n",
    "            curr_ex += 1\n",
    "        if curr_ex >= m:\n",
    "            break \n",
    "\n",
    "    plt.figure()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(display_array, cmap=\"Greys_r\")\n",
    "    \n",
    "    if y is not None: # étiquettes des données en entrée\n",
    "        df = pnd.DataFrame(y.reshape((display_rows, display_cols)))\n",
    "        df = df.astype(int)\n",
    "        print(df.to_string(index=False, header=False))\n",
    "        \n",
    "    if y_predict is not None: # étiquettes des données en sortie (écart / entrée)\n",
    "        print('-'*(display_cols*3-2))\n",
    "        z = pnd.Series(y).combine(pnd.Series(y_predict), func=lambda x, y: y if y != x else -1)\n",
    "        df = pnd.DataFrame(z.reshape((display_rows, display_cols)))\n",
    "        df = df.astype(int, raise_on_error=False)\n",
    "        df.replace(to_replace=-1, value='.', inplace=True)\n",
    "        print(df.to_string(index=False, header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# affichage aléatoire de 100 images et des chiffres correspondants\n",
    "rnd = np.random.permutation(X.shape[0])[0:100]\n",
    "sel = X[rnd,:]\n",
    "res = y[rnd]\n",
    "display_data(sel, res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation du dataset : training set / test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "# pour des raisons d'efficacité, on effectue l'apprentissage sur 10000 échantillons seulement\n",
    "#X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=10000,random_state=0)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=60000,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonction d'exécution générale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# fonction d'exécution générale\n",
    "\n",
    "algos = [] # liste des algorithmes employés\n",
    "df = pnd.DataFrame() # tableau des résultats\n",
    "\n",
    "def run(algo):\n",
    "    global algos, df\n",
    "    \n",
    "    start = timeit.default_timer() # start chrono\n",
    "\n",
    "    algo.fit(X_train, y_train) # algorithme d'apprentissage automatique\n",
    "\n",
    "    y_pred = algo.predict(X_train) # prédictions sur le train set\n",
    "    acc_train = accuracy_score(y_train, y_pred)\n",
    "    print(\"Accuracy on train set: %f\" % acc_train)\n",
    "    \n",
    "    y_pred = algo.predict(X_test) # prédictions sur le test set\n",
    "    acc_test = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy on test set:  %f\" % acc_test)\n",
    "\n",
    "    stop = timeit.default_timer() # stop chrono\n",
    "\n",
    "    # agrégation des résultats\n",
    "    algos.append(algo)\n",
    "    df = df.append([[algo.__class__.__name__, stop-start, acc_train, acc_test]], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K plus proches voisins / K Nearest Neighbors\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# méthode trop lente\n",
    "#algo = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "#run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arbres de décision / Decision Tree\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/tree.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = DecisionTreeClassifier()\n",
    "\n",
    "run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forêts d'arbres décisionnels / Random Forest\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/ensemble.html#random-forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = RandomForestClassifier()\n",
    "\n",
    "run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification naïve bayésienne / Naive Bayes\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/naive_bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = MultinomialNB()\n",
    "\n",
    "run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine à vecteurs de support / Support Vector Machine\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = LinearSVC()\n",
    "\n",
    "run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Régression logistique / Logistic Regression\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/linear_model.html#logistic-regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = LogisticRegression()\n",
    "\n",
    "run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithme du gradient stochastique / Stochastic Gradient Descent\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/sgd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = SGDClassifier()\n",
    "\n",
    "run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réseau de neuronnes / Neural Network\n",
    "\n",
    "Voir : http://scikit-learn.org/stable/modules/neural_networks_supervised.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "algo = MLPClassifier()\n",
    "\n",
    "run(algo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synthèse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.columns = ['algo', 'time', 'train', 'test']\n",
    "df.sort_values(by='test', ascending=False, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage des datasets moyens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dernier algo utilisé\n",
    "algo.fit(X_train, y_train)\n",
    "# prédiction sur toutes les données\n",
    "y_pred = algo.predict(X)\n",
    "# prédiction sur le test set\n",
    "y_pred_test = algo.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display mean tagged digit set\n",
    "z1 = np.concatenate([np.mean(X[y == i], axis=0) for i in range(10)])\n",
    "display_data(z1.reshape((10,28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display mean rightly recognized digit set\n",
    "z3 = np.concatenate([np.mean(X[(y_pred == y) & (y == i)], axis=0) for i in range(10)])\n",
    "display_data(z3.reshape((10,28*28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# display mean wrongly recognized digit set\n",
    "z3 = np.concatenate([np.mean(X[(y_pred != y) & (y == i)], axis=0) for i in range(10)])\n",
    "display_data(z3.reshape((10,28*28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affichage de résultats sur le test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# affichage aléatoire de 100 chiffres et des tags associés\n",
    "rnd = np.random.permutation(X_test.shape[0])[0:100]\n",
    "sel = X_test[rnd,:] # 100 random digits\n",
    "res = y_test[rnd]\n",
    "pred = y_pred_test[rnd]\n",
    "display_data(sel, res, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prévisions sur une image fabriquée manuellement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "var = plt.imread(\"C:/Users/francis/Desktop/test2.bmp\")\n",
    "plt.axis('off')\n",
    "plt.imshow(var, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prédictions de chacun des algorithmes sur l'échantillon\n",
    "sample = [var.flatten()/255]\n",
    "\n",
    "for algo in algos:\n",
    "    prediction = algo.predict(sample)[0]\n",
    "    print(algo.__class__.__name__, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning avec les librairies Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train/test split\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X,y,test_size=10000,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape to be [samples][pixels][width][height]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modèle de base\n",
    "def baseline_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model = baseline_model()\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=1, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test sur l'image\n",
    "var = plt.imread(\"C:/Users/francis/Desktop/test2.bmp\")\n",
    "sample = var.reshape(1, 1, 28, 28)/255\n",
    "model.predict(sample).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def larger_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(30, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Convolution2D(15, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build the model\n",
    "model2 = larger_model()\n",
    "# Fit the model\n",
    "model2.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=1, batch_size=200)\n",
    "# Final evaluation of the model\n",
    "scores = model2.evaluate(X_test, y_test)\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test sur l'image\n",
    "var = plt.imread(\"C:/Users/francis/Desktop/test2.bmp\")\n",
    "sample = var.reshape(1, 1, 28, 28)/255\n",
    "model2.predict(sample).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
